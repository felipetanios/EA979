{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Importing Libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import cv2\n",
    "import csv\n",
    "import pickle\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import imageio\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import dictionary\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Loading Dictionary and Generating Histogram</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'S': 2272, 'L': 675, 'SB': 741, 'I': 336, 'E': 422}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#################################\n",
    "#    Loading Dictionary\n",
    "#################################\n",
    "\n",
    "dic_file = 'dic.p'\n",
    "galaxy_dic = {}\n",
    "galaxy_dic = dictionary.load_obj(dic_file)\n",
    "#print(galaxy_dic)\n",
    "\n",
    "\n",
    "#################################\n",
    "#    Generating Histogram\n",
    "#################################\n",
    "\n",
    "histogram = dictionary.dataset_class_histogram(galaxy_dic)\n",
    "#print(histogram)\n",
    "\n",
    "#################################\n",
    "#    Reducing Classes to\n",
    "\n",
    "#    Sx : Spiral\n",
    "   \n",
    "#    S0 : Lenticular\n",
    "   \n",
    "#    Ix: Irregular\n",
    "   \n",
    "#    Ex : Elliptical\n",
    "#################################\n",
    "\n",
    "\n",
    "#defining morfology\n",
    "for key,value in galaxy_dic.items():\n",
    "    if value == \"S0\" or value == \"S0-a\":\n",
    "        galaxy_dic.update({key: 'L'})\n",
    "\n",
    "for key,value in galaxy_dic.items():\n",
    "    if value[0] == \"S\" and value[1] == \"B\":\n",
    "        galaxy_dic.update({key: 'SB'})\n",
    "        \n",
    "for key,value in galaxy_dic.items():\n",
    "    if value[0] == \"S\" and value[1] != \"B\":\n",
    "        galaxy_dic.update({key: 'S'})\n",
    "        \n",
    "for key,value in galaxy_dic.items():\n",
    "    if value[0] == \"I\":\n",
    "        galaxy_dic.update({key: 'I'})\n",
    "        \n",
    "for key,value in galaxy_dic.items():\n",
    "    if value[0] == \"E\":\n",
    "        galaxy_dic.update({key: 'E'}) \n",
    "\n",
    "for key,value in galaxy_dic.items():\n",
    "    if value[0] == \"|\":\n",
    "        galaxy_dic = dictionary.removekey(galaxy_dic,key)\n",
    "    \n",
    "histogram = dictionary.dataset_class_histogram(galaxy_dic)\n",
    "\n",
    "print(histogram)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creating Labels dictionary and Creating Train, Test and Validation Sets</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "#     Creating Labels dictionary\n",
    "#################################\n",
    "\n",
    "i = 0\n",
    "label_dic = {}\n",
    "for k in galaxy_dic.values():\n",
    "  if k not in label_dic.keys():\n",
    "    label_dic.update({k : i})\n",
    "    i = i + 1\n",
    "\n",
    "number_of_labels = len(label_dic.keys())\n",
    "\n",
    "\n",
    "#########\n",
    "#################################\n",
    "#    Creating Train, Test and Validation Sets\n",
    "#################################\n",
    "#########\n",
    "\n",
    "\n",
    "#########\n",
    "#Separating all set into single type subset\n",
    "#Separating in train, validation and test\n",
    "#########\n",
    "\n",
    "L_galaxy_dic = []\n",
    "for key,value in galaxy_dic.items():\n",
    "    if value == \"L\":\n",
    "        L_galaxy_dic.append(key)\n",
    "\n",
    "L_x_train_names, L_x_test_names = train_test_split(L_galaxy_dic, test_size=0.3)\n",
    "\n",
    "SB_galaxy_dic= []\n",
    "for key,value in galaxy_dic.items():\n",
    "    if value == \"SB\":\n",
    "        SB_galaxy_dic.append(key)\n",
    "\n",
    "SB_x_train_names, SB_x_test_names = train_test_split(SB_galaxy_dic, test_size=0.3)\n",
    "\n",
    "S_galaxy_dic= []\n",
    "for key,value in galaxy_dic.items():\n",
    "    if value == \"S\":\n",
    "        S_galaxy_dic.append(key)\n",
    "\n",
    "S_x_train_names, S_x_test_names = train_test_split(S_galaxy_dic, test_size=0.3)\n",
    "\n",
    "\n",
    "I_galaxy_dic= []\n",
    "for key,value in galaxy_dic.items():\n",
    "    if value == \"I\":\n",
    "        I_galaxy_dic.append(key)\n",
    "\n",
    "I_x_train_names, I_x_test_names = train_test_split(I_galaxy_dic, test_size=0.4)\n",
    "\n",
    "E_galaxy_dic= []\n",
    "for key,value in galaxy_dic.items():\n",
    "    if value == \"E\":\n",
    "        E_galaxy_dic.append(key)\n",
    "\n",
    "E_x_train_names, E_x_test_names = train_test_split(E_galaxy_dic, test_size=0.3)\n",
    "\n",
    "\n",
    "L_x_validation_names, L_x_test_names = train_test_split(L_x_test_names, test_size=0.5)\n",
    "SB_x_validation_names, SB_x_test_names = train_test_split(SB_x_test_names, test_size=0.5)\n",
    "S_x_validation_names, S_x_test_names = train_test_split(S_x_test_names, test_size=0.5)\n",
    "I_x_validation_names, I_x_test_names = train_test_split(I_x_test_names, test_size=0.5)\n",
    "E_x_validation_names, E_x_test_names = train_test_split(E_x_test_names, test_size=0.5)\n",
    "\n",
    "\n",
    "x_train_names = L_x_train_names + SB_x_train_names + S_x_train_names  + E_x_train_names + I_x_train_names\n",
    "x_test_names = L_x_test_names + SB_x_test_names + S_x_test_names  + E_x_test_names + I_x_test_names\n",
    "x_validation_names = L_x_validation_names + SB_x_validation_names + S_x_validation_names + E_x_validation_names + I_x_validation_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Gathering Train, Test and Validation Features</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4446/4446 [00:27<00:00, 163.83it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#########\n",
    "#Gathering Train, Test and Validation Features\n",
    "#########\n",
    "\n",
    "i = 0\n",
    "features_train = []\n",
    "features_test = []\n",
    "features_validation = []\n",
    "labels_train = []\n",
    "labels_test = []\n",
    "labels_validation = []\n",
    "\n",
    "\n",
    "\n",
    "for path_to_image in tqdm(glob.glob(\"./images/png-grey/*.png\")):\n",
    "    # print(path_to_image[18:-4])\n",
    "    name = path_to_image[18:-4]\n",
    "    name_to_open = './images/png-grey/' + path_to_image[18:]\n",
    "\n",
    "    if name in x_train_names:\n",
    "    \tim = cv2.resize(cv2.imread(name_to_open), (224, 224)).astype(np.float32)\n",
    "    \t#im = im.transpose((2,0,1))\n",
    "    \t# im = np.expand_dims(im, axis=0)\n",
    "    \tfeatures_train.append(im)\n",
    "    \tidx = label_dic[galaxy_dic[name]]\n",
    "    \tlabel_train = idx\n",
    "    \tlabels_train.append(label_train)\n",
    "\n",
    "\n",
    "    if name in x_test_names:\n",
    "    \tim = cv2.resize(cv2.imread(name_to_open), (224, 224)).astype(np.float32)\n",
    "    \t#im = im.transpose((2,0,1))\n",
    "    \t# im = np.expand_dims(im, axis=0)\n",
    "    \tfeatures_test.append(im)\n",
    "    \tidx = label_dic[galaxy_dic[name]]\n",
    "    \tlabel_test = idx\n",
    "    \tlabels_test.append(label_test)\n",
    "\n",
    "    if name in x_validation_names:\n",
    "    \tim = cv2.resize(cv2.imread(name_to_open), (224, 224)).astype(np.float32)\n",
    "    \t#im = im.transpose((2,0,1))\n",
    "    \t# im = np.expand_dims(im, axis=0)\n",
    "    \tfeatures_validation.append(im)\n",
    "    \tidx = label_dic[galaxy_dic[name]]\n",
    "    \tlabel_validation = idx\n",
    "    \tlabels_validation.append(label_validation)\n",
    "\n",
    "\n",
    "\n",
    "features_train = np.array(features_train)\n",
    "features_test = np.array(features_test)\n",
    "features_validation = np.array(features_validation)\n",
    "labels_train = np.array(labels_train)\n",
    "labels_test = np.array(labels_test)\n",
    "\n",
    "\n",
    "x_train = features_train\n",
    "x_validation = features_validation\n",
    "x_test = features_test\n",
    "y_train = labels_train\n",
    "y_validation = labels_validation\n",
    "y_test = labels_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Defining Training parameters</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (63, 255, 255, 3)\n",
      "63 train samples\n",
      "687 test samples\n",
      "y_train shape: (63, 5)\n",
      "63 train samples\n",
      "687 test samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#########\n",
    "#Defining Training parameters\n",
    "#########\n",
    "\n",
    "#O numero de passos vai ser len(x_train)/(batch_size)\n",
    "batch_size = 64 #numero de amostras por gradiente\n",
    "num_classes = number_of_labels # numero de classes do cifar10\n",
    "epochs = 1 #numero de epocas para treinar o modelo\n",
    "data_augmentation = True\n",
    "\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "y_validation = keras.utils.to_categorical(y_validation, num_classes)\n",
    "\n",
    "\n",
    "print('y_train shape:', y_train.shape)\n",
    "# print ('size of first dimention ', y_train[0][0])\n",
    "print(y_train.shape[0], 'train samples')\n",
    "print(y_test.shape[0], 'test samples')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Defining Network Topology (VGG16z)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########\n",
    "#Defining Network Topology(VGG16z)\n",
    "#########\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1,1), input_shape=x_train.shape[1:],data_format='channels_last'))\n",
    "model.add(Convolution2D(64, (3,3), activation='relu',data_format='channels_last'))\n",
    "model.add(ZeroPadding2D((1,1),data_format='channels_last'))\n",
    "model.add(Convolution2D(64, (3,3), activation='relu',data_format='channels_last'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2),data_format='channels_last'))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1),data_format='channels_last'))\n",
    "model.add(Convolution2D(128, (3,3), activation='relu',data_format='channels_last'))\n",
    "model.add(ZeroPadding2D((1,1),data_format='channels_last'))\n",
    "model.add(Convolution2D(128, (3,3), activation='relu',data_format='channels_last'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2),data_format='channels_last'))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1),data_format='channels_last'))\n",
    "model.add(Convolution2D(256, (3,3), activation='relu',data_format='channels_last'))\n",
    "model.add(ZeroPadding2D((1,1),data_format='channels_last'))\n",
    "model.add(Convolution2D(256, (3,3), activation='relu',data_format='channels_last'))\n",
    "model.add(ZeroPadding2D((1,1),data_format='channels_last'))\n",
    "model.add(Convolution2D(256, (3,3), activation='relu',data_format='channels_last'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2),data_format='channels_last'))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1),data_format='channels_last'))\n",
    "model.add(Convolution2D(512, (3,3), activation='relu',data_format='channels_last'))\n",
    "model.add(ZeroPadding2D((1,1),data_format='channels_last'))\n",
    "model.add(Convolution2D(512, (3,3), activation='relu',data_format='channels_last'))\n",
    "model.add(ZeroPadding2D((1,1),data_format='channels_last'))\n",
    "model.add(Convolution2D(512, (3,3), activation='relu',data_format='channels_last'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2),data_format='channels_last'))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1),data_format='channels_last'))\n",
    "model.add(Convolution2D(512, (3,3), activation='relu',data_format='channels_last'))\n",
    "model.add(ZeroPadding2D((1,1),data_format='channels_last'))\n",
    "model.add(Convolution2D(512, (3,3), activation='relu',data_format='channels_last'))\n",
    "model.add(ZeroPadding2D((1,1),data_format='channels_last'))\n",
    "model.add(Convolution2D(512, (3,3), activation='relu',data_format='channels_last'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2),data_format='channels_last'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "# RMS usa back propagation [RMS(w) eh em funcao de w-1] quadratico\n",
    "\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "plot_model(model, to_file='model.png')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training CNN</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using data augmentation.\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Train on 63 samples, validate on 683 samples\n",
      "Epoch 1/1\n",
      "63/63 [==============================] - 126s 2s/step - loss: 1.6264 - acc: 0.1270 - val_loss: 8.0708 - val_acc: 0.4993\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#########\n",
    "#Training the CNN\n",
    "#########\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# ao invez de pegar todos os treinos e testes, o programa pega apenas uma porcao\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_validation, y_validation),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=True)  # randomly flip images\n",
    "\n",
    "    print (\"augmenting data\")\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    print (\"data augmented\")\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size), \n",
    "                        steps_per_epoch=x_train.shape[0] // batch_size, \n",
    "                        epochs=epochs, validation_data=(x_validation, y_validation))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Getting Results</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4686b18ed0b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Resultado do teste final de acerto da rede\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#########\n",
    "#Getting Results\n",
    "#########\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"Resultado do teste final de acerto da rede\")\n",
    "print(score)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#keras get_layer: retorna a layer: podemos usar para ver o estado final dos filtros usados (ja que sao 5x5)\n",
    "#visualize single neuron ->> output para apresentação\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Y_pred = model.predict(x_test, batch_size=batch_size, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.99969125e-01   1.64386511e-05   1.26375317e-05   1.65746911e-07\n",
      "    1.61980063e-06]\n",
      " [  9.99903798e-01   4.96908979e-05   3.93847185e-05   8.84367182e-07\n",
      "    6.31536204e-06]\n",
      " [  9.99992132e-01   4.31862827e-06   3.27619682e-06   2.69725025e-08\n",
      "    3.17913930e-07]\n",
      " ..., \n",
      " [  9.99999046e-01   5.72607689e-07   4.00848251e-07   1.51866197e-09\n",
      "    2.82330799e-08]\n",
      " [  9.99998927e-01   5.93250832e-07   4.32683464e-07   1.70635750e-09\n",
      "    2.92510531e-08]\n",
      " [  9.84149635e-01   6.72753248e-03   6.16854057e-03   7.64608267e-04\n",
      "    2.18970468e-03]]\n",
      "145\n",
      "[[ 0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.]\n",
      " ..., \n",
      " [ 0.  1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(Y_pred)\n",
    "\n",
    "for i in range(len(Y_pred)):\n",
    "    \n",
    "print (Y_pred)\n",
    "print (y_pred)\n",
    "print(y_test)\n",
    "# print('Confusion Matrix')\n",
    "# print(confusion_matrix(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
